# ğŸ¬ AI Motion Capture System v2.0

**A sophisticated motion capture system with a beautiful modern GUI**

State-of-the-art whole-body tracking from single-camera video using RTMPose and RTMDet.

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.9+-green.svg)](https://www.python.org/)

## ğŸŒŸ Features

### Core Capabilities
- **ğŸ¯ 133-Keypoint Tracking**: Full body (17) + feet (6) + face (68) + hands (2Ã—21)
- **âœ‹ Advanced Finger Articulation**: Per-finger curl detection, spread analysis, gesture recognition
- **ğŸ‘¥ Multi-Person Tracking**: ByteTrack for robust identity persistence across frames
- **ğŸ¨ Temporal Smoothing**: One-Euro filters for smooth, responsive motion
- **ğŸ“¦ Export Formats**: JSON, CSV, BVH (with extensibility for FBX, USD)
- **âš¡ Real-Time Performance**: Optimized with ONNX Runtime (CPU/CUDA/DirectML/CoreML)

### Technical Excellence
- **State-of-the-Art Models**:
  - **RTMDet** (55+ mAP COCO) for person detection
  - **RTMPose-X** (76.6% AP COCO-WholeBody) for pose estimation
  - Apache 2.0 licensed from OpenMMLab

- **Production-Ready Architecture**:
  - Modular, extensible design
  - Comprehensive error handling
  - Configuration management
  - Progress tracking and logging

## ğŸ“Š Comparison with Previous Implementation

| Feature | Previous (OpenVINO Basic) | **New (RTMPose Advanced)** |
|---------|---------------------------|----------------------------|
| **Keypoints** | 18 body + 21Ã—2 hands | **133 (body+face+hands unified)** |
| **Accuracy** | ~65% AP | **76.6% AP** âš¡ |
| **Finger Detail** | Basic 3-state | **Per-finger curl + gestures** |
| **Tracking** | No ID persistence | **ByteTrack with ReID** |
| **3D Pose** | âŒ None | âœ… Framework ready |
| **Export** | JSON/CSV | **JSON/CSV/BVH** |
| **Visualization** | Basic 2D | **Advanced multi-viewport ready** |

## ğŸš€ Quick Start

### Installation

```bash
# Navigate to repository
cd MOOOOOOCAP

# Install dependencies
pip install -r requirements.txt

# Launch the application
python run.py
```

### Using the GUI

1. **Open a video**
   - Click "ğŸ“‚ Open Video" or press `Ctrl+O`
   - Select your video file (MP4, AVI, MOV, MKV supported)

2. **Configure settings** (in the Control Panel on the right)
   - Select device (CPU or CUDA GPU)
   - Adjust detection and pose confidence thresholds
   - Enable/disable multi-person tracking
   - Customize visualization options

3. **Process the video**
   - Click "ğŸ¯ Process Video" to start motion capture
   - Watch real-time skeleton overlay on the video
   - View statistics in the Visualization panel
   - Monitor hand tracking details in the Hands tab

4. **Export results**
   - Click "ğŸ’¾ Export" when processing is complete
   - Choose format: JSON, CSV, or BVH
   - Results include all 133 keypoints and hand articulation data

## ğŸ“ Architecture

### Pipeline Overview

```
Input Video
    â†“
[Person Detection] â† RTMDet (real-time, high accuracy)
    â†“
[Pose Estimation] â† RTMPose (133 keypoints, whole-body)
    â†“
[Multi-Person Tracking] â† ByteTrack (identity persistence)
    â†“
[Temporal Smoothing] â† One-Euro Filter (smooth motion)
    â†“
[3D Pose Lifting] â† Optional, kinematic-based
    â†“
[Export] â†’ JSON/CSV/BVH
```

### Key Components

- **`mocap_app/types.py`**: Core data structures (BoundingBox, WholeBodyPose, etc.)
- **`mocap_app/config.py`**: Configuration management system
- **`mocap_app/models/`**: AI models (detector, pose estimator)
- **`mocap_app/tracking/`**: Multi-person tracking (ByteTrack)
- **`mocap_app/filters/`**: Temporal smoothing (One-Euro filter)
- **`mocap_app/pipeline/`**: Main processing pipeline orchestration
- **`mocap_app/gui/`**: Beautiful dark-themed GUI (Qt/PySide6)
- **`mocap_app/export/`**: Export to various formats (JSON, CSV, BVH)
- **`mocap_app/app.py`**: Main application entry point

## ğŸ”§ Configuration

Create a `config.yaml` file for custom settings:

```yaml
device: cuda  # cpu, cuda, directml, coreml

detection:
  model_name: rtmdet-nano  # rtmdet-{nano,s,m,l}
  confidence_threshold: 0.5
  max_persons: 10

pose:
  model_name: rtmpose-x  # rtmpose-{t,s,m,l,x}
  use_wholebody: true
  confidence_threshold: 0.3

tracking:
  enabled: true
  tracker_type: bytetrack
  track_thresh: 0.6

filtering:
  enabled: true
  one_euro_min_cutoff: 1.0
  one_euro_beta: 0.7

export:
  formats: [json, csv]
  output_dir: data/exports
```

Then use it:

```bash
python -m mocap_app.cli --video input.mp4 --config config.yaml --output results.json
```

## ğŸ“š Model Zoo

### Detection Models

| Model | Input Size | Speed | mAP | Use Case |
|-------|-----------|-------|-----|----------|
| rtmdet-nano | 640Ã—640 | âš¡âš¡âš¡ | 40.9 | Real-time applications |
| rtmdet-s | 640Ã—640 | âš¡âš¡ | 44.5 | Balanced |
| rtmdet-m | 640Ã—640 | âš¡ | 49.3 | High accuracy |

### Pose Models

| Model | Input Size | Speed | AP | Keypoints | Use Case |
|-------|-----------|-------|-----|-----------|----------|
| rtmpose-t | 256Ã—192 | âš¡âš¡âš¡ | 65.9 | 17 | Fast body tracking |
| rtmpose-m-wholebody | 256Ã—192 | âš¡âš¡ | 60.6 | 133 | Balanced whole-body |
| rtmpose-x-wholebody | 384Ã—288 | âš¡ | **76.6** | 133 | **Best accuracy** |

## ğŸ¯ Use Cases

### Animation & VFX
- Character animation reference
- Motion retargeting to 3D rigs
- Virtual production

### Gaming
- Real-time player tracking
- Gesture controls
- Motion-based gameplay

### Sports Analysis
- Biomechanics analysis
- Form correction
- Performance tracking

### Healthcare & Fitness
- Physical therapy monitoring
- Exercise form analysis
- Rehabilitation tracking

## ğŸ“„ License & Attribution

### Project License
This project is licensed under the **Apache License 2.0**.

### Model Licenses
All models are from OpenMMLab and licensed under **Apache 2.0**:

- **RTMDet**: https://github.com/open-mmlab/mmdetection (Apache 2.0)
- **RTMPose**: https://github.com/open-mmlab/mmpose (Apache 2.0)
- **ByteTrack**: Clean-room implementation based on paper (MIT-compatible)

### Dependencies
- PyTorch: BSD-3-Clause
- ONNX Runtime: MIT
- OpenCV: Apache 2.0
- NumPy/SciPy: BSD-3-Clause
- PySide6: LGPL-3.0 (allows commercial use)

**âœ… Fully commercial-use friendly - no GPL, no MediaPipe!**

## ğŸ› ï¸ Development

### Project Structure

```
MOOOOOOCAP/
â”œâ”€â”€ mocap_app/                     # Main application package
â”‚   â”œâ”€â”€ __init__.py               # Package initialization
â”‚   â”œâ”€â”€ types.py                  # Core data structures
â”‚   â”œâ”€â”€ config.py                 # Configuration system
â”‚   â”œâ”€â”€ app.py                    # Application entry point
â”‚   â”œâ”€â”€ models/                   # AI model components
â”‚   â”‚   â”œâ”€â”€ detector.py          # Person detection (RTMDet)
â”‚   â”‚   â””â”€â”€ pose_estimator.py   # Pose estimation (RTMPose)
â”‚   â”œâ”€â”€ tracking/                 # Multi-person tracking
â”‚   â”‚   â””â”€â”€ bytetrack.py         # ByteTrack implementation
â”‚   â”œâ”€â”€ filters/                  # Temporal smoothing
â”‚   â”‚   â””â”€â”€ one_euro.py          # One-Euro filter
â”‚   â”œâ”€â”€ pipeline/                 # Processing pipeline
â”‚   â”œâ”€â”€ gui/                      # Modern dark-themed GUI
â”‚   â”‚   â”œâ”€â”€ main_window.py       # Main application window
â”‚   â”‚   â”œâ”€â”€ video_widget.py      # Video player with timeline
â”‚   â”‚   â”œâ”€â”€ control_panel.py     # Settings controls
â”‚   â”‚   â””â”€â”€ visualization_widget.py  # Stats and 3D view
â”‚   â”œâ”€â”€ export/                   # Export functionality
â”‚   â””â”€â”€ utils/                    # Utility functions
â”œâ”€â”€ run.py                        # Application launcher
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ config.yaml                   # Configuration file (optional)
â”œâ”€â”€ data/                         # Data directory
â”‚   â”œâ”€â”€ models/                   # Downloaded AI models
â”‚   â””â”€â”€ exports/                  # Exported results
â””â”€â”€ docs/                         # Documentation
```

### Adding New Features

The modular architecture makes it easy to extend:

1. **New AI Models**: Add to `mocap_app/models/`
2. **New Tracking Algorithms**: Implement in `mocap_app/tracking/`
3. **New Export Formats**: Add to `mocap_app/export/`
4. **GUI Enhancements**: Extend widgets in `mocap_app/gui/`
5. **3D Visualization**: Enhance `visualization_widget.py` with PyOpenGL

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ Support

- **Issues**: https://github.com/yourusername/MOOOOOOCAP/issues
- **Discussions**: https://github.com/yourusername/MOOOOOOCAP/discussions
- **Documentation**: See `docs/` directory

## ğŸ“ Citations

If you use this project in your research, please cite the original works:

```bibtex
@inproceedings{rtmpose2023,
  title={RTMPose: Real-Time Multi-Person Pose Estimation based on MMPose},
  author={Jiang, Tao and Lu, Peng and Zhang, Li and others},
  booktitle={arXiv preprint arXiv:2303.07399},
  year={2023}
}

@article{bytetrack2022,
  title={ByteTrack: Multi-Object Tracking by Associating Every Detection Box},
  author={Zhang, Yifu and others},
  journal={ECCV},
  year={2022}
}
```

## ğŸŒŸ Acknowledgments

- **OpenMMLab** for RTMDet and RTMPose
- **ByteTrack** authors for the tracking algorithm
- One-Euro Filter authors for smooth filtering

---

**Built with â¤ï¸ for the motion capture community**
